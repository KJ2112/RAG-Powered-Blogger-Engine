{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12622653,"sourceType":"datasetVersion","datasetId":7975228}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n\nfor root, dirs, files in os.walk(\"/kaggle/input\"):\n    print(root)\n\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-11T09:49:37.045777Z","iopub.execute_input":"2025-12-11T09:49:37.046302Z","iopub.status.idle":"2025-12-11T09:49:37.326130Z","shell.execute_reply.started":"2025-12-11T09:49:37.046278Z","shell.execute_reply":"2025-12-11T09:49:37.325464Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/metadata.pkl\n/kaggle/input/faiss.index\n/kaggle/input\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install faiss-cpu --no-cache-dir","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T09:49:38.377987Z","iopub.execute_input":"2025-12-11T09:49:38.378729Z","iopub.status.idle":"2025-12-11T09:49:43.680685Z","shell.execute_reply.started":"2025-12-11T09:49:38.378706Z","shell.execute_reply":"2025-12-11T09:49:43.679903Z"}},"outputs":[{"name":"stdout","text":"Collecting faiss-cpu\n  Downloading faiss_cpu-1.13.1-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nDownloading faiss_cpu-1.13.1-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m189.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.13.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nimport torch\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T10:02:10.237428Z","iopub.execute_input":"2025-12-11T10:02:10.238082Z","iopub.status.idle":"2025-12-11T10:02:10.241648Z","shell.execute_reply.started":"2025-12-11T10:02:10.238058Z","shell.execute_reply":"2025-12-11T10:02:10.240819Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ‚îÄ‚îÄ‚îÄ Cell 1: Imports & load index ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nimport faiss\nimport pickle\nimport numpy as np\nimport pandas as pd\nfrom sentence_transformers import SentenceTransformer\n\n# 1) Load FAISS index & metadata\nindex = faiss.read_index(\"/kaggle/input/faiss.index\")\nwith open(\"/kaggle/input/metadata.pkl\", \"rb\") as f:\n    df = pickle.load(f)\n\n# 2) Init your embedder\nmodel = SentenceTransformer(\"all-MiniLM-L6-v2\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T09:49:46.696093Z","iopub.execute_input":"2025-12-11T09:49:46.696836Z","iopub.status.idle":"2025-12-11T09:50:27.373248Z","shell.execute_reply.started":"2025-12-11T09:49:46.696804Z","shell.execute_reply":"2025-12-11T09:50:27.372636Z"}},"outputs":[{"name":"stderr","text":"2025-12-11 09:50:00.222516: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765446600.404393      38 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765446600.468532      38 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80060cea5c5f498098cb30935de2f30a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a37709dc38f84cb0a62203cb1bbcfd38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19a595b8460443459c0e91cc6bf6a03d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adb5c4048eda479e82ea9b4b09efbe60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76c17c3754d3465e9a8c320b81b877b6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71429a05c7f84994a6a27569de748bf6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe8775c633204f789e9baafd6dbff09b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"732647548c8a4673a66eeb4c45cb65b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03c583d8b07b4ce1af80a32848a8a252"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4de6ee3d9c84bf6b2c7974bc0f0d09d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f72398c4b23e4b3a9bb068edbb6ee3da"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# ‚îÄ‚îÄ‚îÄ Cell 2: Pure dense‚Äêretrieval search function ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\ndef search_titles_urls(query: str, k: int = 5) -> pd.DataFrame:\n    \"\"\"\n    Returns the top‚Äêk (title, url) for the given query using\n    MiniLM embeddings + FAISS inner‚Äêproduct search.\n    \"\"\"\n    qv = model.encode([query]).astype(\"float32\")\n    D, I = index.search(qv, k)\n\n    # grab & dedupe\n    res = (\n        df.iloc[I[0]][[\"title\",\"url\"]]\n        .drop_duplicates()\n        .reset_index(drop=True)\n    )\n    return res\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T09:50:58.033509Z","iopub.execute_input":"2025-12-11T09:50:58.033778Z","iopub.status.idle":"2025-12-11T09:50:58.038654Z","shell.execute_reply.started":"2025-12-11T09:50:58.033758Z","shell.execute_reply":"2025-12-11T09:50:58.037999Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\nfrom IPython.display import HTML, display\n\n# 1) Run your search as before\nquery   = \"agentic ai\"\nresults = search_titles_urls(query, k=10)\n\n# 2) Convert the 'url' column into clickable links\nresults_html = results.to_html(\n    escape=False,\n    index=False,\n    formatters={\n        \"url\": lambda x: f'<a href=\"{x}\" target=\"_blank\">{x}</a>'\n    }\n)\n\n# 3) Display as HTML\ndisplay(HTML(results_html))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T09:51:08.193213Z","iopub.execute_input":"2025-12-11T09:51:08.193488Z","iopub.status.idle":"2025-12-11T09:51:08.734249Z","shell.execute_reply.started":"2025-12-11T09:51:08.193467Z","shell.execute_reply":"2025-12-11T09:51:08.733613Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40d38c031f9c49fbbeea32b8ba2946f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>title</th>\n      <th>url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>Agentic AI. Hello everyone, and welcome! We‚Äôve seen‚Ä¶ | by Servifyspheresolutions | Jun, 2025 | Medium</td>\n      <td><a href=\"https://medium.com/@servifyspheresolutions/agentic-ai-658024c6c4c8\" target=\"_blank\">https://medium.com/@servifyspheresolutions/agentic-ai-658024c6c4c8</a></td>\n    </tr>\n    <tr>\n      <td>Top 5 Agentic AI Frameworks to Watch in 2025 | by Future AGI | Jun, 2025 | Medium</td>\n      <td><a href=\"https://medium.com/@future_agi/top-5-agentic-ai-frameworks-to-watch-in-2025-9573c09da488\" target=\"_blank\">https://medium.com/@future_agi/top-5-agentic-ai-frameworks-to-watch-in-2025-9573c09da488</a></td>\n    </tr>\n    <tr>\n      <td>Agent VII ‚Äî Navigating the Agentic AI Landscape: A Deep Dive into Frameworks Powering Next-Gen AI Agents | by DhanushKumar | May, 2025 | Medium</td>\n      <td><a href=\"https://medium.com/@danushidk507/agent-vii-navigating-the-agentic-ai-landscape-a-deep-dive-into-frameworks-powering-next-gen-ai-c3b18102408e\" target=\"_blank\">https://medium.com/@danushidk507/agent-vii-navigating-the-agentic-ai-landscape-a-deep-dive-into-frameworks-powering-next-gen-ai-c3b18102408e</a></td>\n    </tr>\n    <tr>\n      <td>How to Build Agentic AI: A Comprehensive Guide üß† | GCS Network</td>\n      <td><a href=\"https://globalcybersecuritynetwork.com/blog/how-to-build-agentic-ai/\" target=\"_blank\">https://globalcybersecuritynetwork.com/blog/how-to-build-agentic-ai/</a></td>\n    </tr>\n    <tr>\n      <td>Getting Started Guide to Agentic AI | Chai</td>\n      <td><a href=\"https://www.chaione.com/start\" target=\"_blank\">https://www.chaione.com/start</a></td>\n    </tr>\n    <tr>\n      <td>Agentic AI is in the aiR | Relativity Blog</td>\n      <td><a href=\"https://www.relativity.com/blog/agentic-ai-is-in-the-air/\" target=\"_blank\">https://www.relativity.com/blog/agentic-ai-is-in-the-air/</a></td>\n    </tr>\n    <tr>\n      <td>Agentic AI: A Technical Deep Dive Toward Next-Generation Intelligence | by Adnan Masood, PhD. | Medium</td>\n      <td><a href=\"https://medium.com/@adnanmasood/agentic-ai-a-technical-deep-dive-toward-next-generation-intelligence-140b35b71ce5\" target=\"_blank\">https://medium.com/@adnanmasood/agentic-ai-a-technical-deep-dive-toward-next-generation-intelligence-140b35b71ce5</a></td>\n    </tr>\n    <tr>\n      <td>‚ÄãAgentic AI in 2025: A Deep Dive into Autonomous Intelligence and Its Future |QualityPoint Technologies (QPT)</td>\n      <td><a href=\"https://www.blog.qualitypointtech.com/2025/04/agentic-ai-in-2025-deep-dive-into.html\" target=\"_blank\">https://www.blog.qualitypointtech.com/2025/04/agentic-ai-in-2025-deep-dive-into.html</a></td>\n    </tr>\n    <tr>\n      <td>Agentic AI Architectures And Design Patterns | by Anil Jain | AI / ML Architect | Data Architect | Medium</td>\n      <td><a href=\"https://medium.com/@anil.jain.baba/agentic-ai-architectures-and-design-patterns-288ac589179a\" target=\"_blank\">https://medium.com/@anil.jain.baba/agentic-ai-architectures-and-design-patterns-288ac589179a</a></td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Cell: Load HF summarization model (lightweight)\nMODEL_NAME = \"google/flan-t5-base\"   # light, instruction-tuned, good balance\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using device:\", device)\n\ntokenizer_summ = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel_summ = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)\nmodel_summ.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T10:02:37.861208Z","iopub.execute_input":"2025-12-11T10:02:37.861498Z","iopub.status.idle":"2025-12-11T10:02:47.318596Z","shell.execute_reply.started":"2025-12-11T10:02:37.861475Z","shell.execute_reply":"2025-12-11T10:02:47.317839Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d8344aa4642647a2a8db858b9e7b594a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"077afe3e35134944acb6d11fef6d6b42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bccdb2479c354dceaad1663f8456ee55"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98bd2a4ab16e4d57b2bf848bad2397da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a7e8d6191ee4992a4be16f727813040"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55a80fb6c9e0426fa311ead5006290a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dfcd00a1ece4bf09c576ded9554fca4"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseGatedActDense(\n              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n              (wo): Linear(in_features=2048, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): NewGELUActivation()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Cell: helper to retrieve chunk text from df row (tries common column names)\ndef get_chunk_text_from_row(row):\n    # try common column names (adapt if your df uses something else)\n    possible_cols = ['text','chunk_text','content','body','clean_text','article','chunk']\n    for c in possible_cols:\n        if c in row.index and isinstance(row[c], str) and len(row[c].strip())>0:\n            return row[c]\n    # Fallback: if none found, try combining title + url (still better than nothing)\n    title = row['title'] if 'title' in row.index else ''\n    url = row['url'] if 'url' in row.index else ''\n    return f\"{title}\\n{url}\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T10:02:57.983302Z","iopub.execute_input":"2025-12-11T10:02:57.984026Z","iopub.status.idle":"2025-12-11T10:02:57.990509Z","shell.execute_reply.started":"2025-12-11T10:02:57.983988Z","shell.execute_reply":"2025-12-11T10:02:57.989724Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Cell: summarizer function\ndef summarize_text(text, max_tokens=80):\n    # keep input length reasonable for FLAN-T5; trim very long chunks\n    max_input_chars = 3000\n    if len(text) > max_input_chars:\n        text = text[:max_input_chars]  # simple truncation; can be improved\n\n    prompt = f\"Summarize the following text in 2-3 short sentences:\\n\\n{text}\"\n    inputs = tokenizer_summ(prompt, truncation=True, return_tensors=\"pt\").to(device)\n\n    # generation params - short summary, deterministic beams\n    out = model_summ.generate(\n        **inputs,\n        max_new_tokens=max_tokens,\n        num_beams=4,\n        early_stopping=True,\n        no_repeat_ngram_size=3\n    )\n    summary = tokenizer_summ.decode(out[0], skip_special_tokens=True)\n    return summary\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T10:03:16.639540Z","iopub.execute_input":"2025-12-11T10:03:16.640184Z","iopub.status.idle":"2025-12-11T10:03:16.645862Z","shell.execute_reply.started":"2025-12-11T10:03:16.640154Z","shell.execute_reply":"2025-12-11T10:03:16.644884Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Cell: search + summarization - minimal changes to existing pipeline\ndef search_with_summaries(query: str, k: int = 5, summarise_each=True):\n    \"\"\"\n    Returns a DataFrame with columns: title, summary (if summarise_each), url\n    Uses the existing SentenceTransformer embedder (named `model` in your notebook),\n    the FAISS index (named `index`), and the metadata df (named `df`).\n    \"\"\"\n    # 1) encode query (your existing model variable from sentence-transformers)\n    qv = model.encode([query]).astype(\"float32\")   # model is SentenceTransformer\n    D, I = index.search(qv, k)                     # I is shape (1,k)\n    idxs = I[0].tolist()\n\n    # 2) build result df from the metadata df rows\n    results = df.iloc[idxs].copy().reset_index(drop=True)\n\n    # 3) optionally summarize each chunk\n    if summarise_each:\n        summaries = []\n        for i, row in results.iterrows():\n            txt = get_chunk_text_from_row(row)\n            try:\n                summ = summarize_text(txt, max_tokens=70)   # ~3 short sentences\n            except Exception as e:\n                summ = \"Summary generation failed\"\n                print(\"summarize error:\", e)\n            summaries.append(summ)\n        results['summary'] = summaries\n    else:\n        results['summary'] = \"\"\n\n    # keep only the fields we want to show\n    show_cols = []\n    if 'title' in results.columns: show_cols.append('title')\n    show_cols.append('summary')\n    if 'url' in results.columns: show_cols.append('url')\n\n    return results[show_cols]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T10:03:43.814444Z","iopub.execute_input":"2025-12-11T10:03:43.814721Z","iopub.status.idle":"2025-12-11T10:03:43.821641Z","shell.execute_reply.started":"2025-12-11T10:03:43.814700Z","shell.execute_reply":"2025-12-11T10:03:43.820429Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Cell: run search_with_summaries and show clickable links\nquery = \"Attention mechanisms\"   # or input from your UI\nresults = search_with_summaries(query, k=10, summarise_each=True)\n\n# make url clickable in HTML\nresults_html = results.to_html(\n    escape=False,\n    index=False,\n    formatters={\n        'url': lambda x: f'<a href=\"{x}\" target=\"_blank\">{x}</a>'\n    }\n)\nfrom IPython.display import HTML, display\ndisplay(HTML(results_html))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-11T10:04:25.213953Z","iopub.execute_input":"2025-12-11T10:04:25.214549Z","iopub.status.idle":"2025-12-11T10:04:34.678153Z","shell.execute_reply.started":"2025-12-11T10:04:25.214526Z","shell.execute_reply":"2025-12-11T10:04:34.677456Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89496b87a17a4d488675c8feca0f7dae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>title</th>\n      <th>summary</th>\n      <th>url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>What is an attention mechanism? | IBM</td>\n      <td>An attention mechanism is a machine learning technique that directs deep learning models to prioritize (or attend to) the most relevant parts of input data.</td>\n      <td><a href=\"https://www.ibm.com/think/topics/attention-mechanism\" target=\"_blank\">https://www.ibm.com/think/topics/attention-mechanism</a></td>\n    </tr>\n    <tr>\n      <td>Attention and Memory in Deep Learning and NLP ¬∑ Denny's Blog</td>\n      <td>Attention Mechanisms in Neural Networks are loosely based on the visual attention mechanism found in humans.</td>\n      <td><a href=\"https://dennybritz.com/posts/wildml/attention-and-memory-in-deep-learning-and-nlp/\" target=\"_blank\">https://dennybritz.com/posts/wildml/attention-and-memory-in-deep-learning-and-nlp/</a></td>\n    </tr>\n    <tr>\n      <td>The Mathematics of Attention Mechanisms: Building Self-Attention from First Principles | by Abduldattijo | Generative AI</td>\n      <td>The Mathematics of Attention Mechanisms: Building Self-Attention from First Principles | by Abduldattijo | Generative AI Sitemap Open in app Sign up Sign in Medium Logo Write Sign in Genreative AI  Follow publication Stay updated with the latest news, research, and developments in the world of generative AI. We</td>\n      <td><a href=\"https://generativeai.pub/the-mathematics-of-attention-mechanisms-building-self-attention-from-first-principles-b9895e9ee491\" target=\"_blank\">https://generativeai.pub/the-mathematics-of-attention-mechanisms-building-self-attention-from-first-principles-b9895e9ee491</a></td>\n    </tr>\n    <tr>\n      <td>5 Attention Mechanism Insights Every AI Developer Should Know</td>\n      <td>AI Education October 1, 2024 Written by Tobias Jaeckel Unstructured Data Management Platform ¬ª AI Education ¬ª Attention Mechanism: Everything You Need to Know</td>\n      <td><a href=\"https://shelf.io/blog/attention-mechanism/\" target=\"_blank\">https://shelf.io/blog/attention-mechanism/</a></td>\n    </tr>\n    <tr>\n      <td>5 Attention Mechanism Insights Every AI Developer Should Know</td>\n      <td>AI Education October 1, 2024 Written by Tobias Jaeckel Unstructured Data Management Platform ¬ª AI Education ¬ª Attention Mechanism: Everything You Need to Know</td>\n      <td><a href=\"https://shelf.io/blog/attention-mechanism/\" target=\"_blank\">https://shelf.io/blog/attention-mechanism/</a></td>\n    </tr>\n    <tr>\n      <td>Rethinking Thinking: How Do Attention Mechanisms Actually Work? | Towards Data Science</td>\n      <td>Rethinking Thinking: How Do Attention Mechanisms Actually Work?</td>\n      <td><a href=\"https://towardsdatascience.com/rethinking-thinking-how-do-attention-mechanisms-actually-work-a6f67d313f99/\" target=\"_blank\">https://towardsdatascience.com/rethinking-thinking-how-do-attention-mechanisms-actually-work-a6f67d313f99/</a></td>\n    </tr>\n    <tr>\n      <td>Day 58: Attention Mechanisms ‚Äî Foundation of Transformer Models | by Adithya Prasad Pandelu | Medium</td>\n      <td>Adithya Prasad Pandelu explores the foundation of modern AI models.</td>\n      <td><a href=\"https://medium.com/@bhatadithya54764118/day-58-attention-mechanisms-foundation-of-transformer-models-c3139d3c0e79\" target=\"_blank\">https://medium.com/@bhatadithya54764118/day-58-attention-mechanisms-foundation-of-transformer-models-c3139d3c0e79</a></td>\n    </tr>\n    <tr>\n      <td>Attention Mechanism in Deep Learning : Simplified | by Prakhar Ganesh | Medium</td>\n      <td>In an attempt to borrow inspiration from how a human mind works, researchers in Deep Learning have tried replicating this behavior using what is known as the ‚Äòattention mechanism‚Äô</td>\n      <td><a href=\"https://medium.com/@prakhargannu/attention-mechanism-in-deep-learning-simplified-d6a5830a079d\" target=\"_blank\">https://medium.com/@prakhargannu/attention-mechanism-in-deep-learning-simplified-d6a5830a079d</a></td>\n    </tr>\n    <tr>\n      <td>A study on Attention mechanism. This study shows the impact, evolution‚Ä¶ | by Nilesh Barla | PerceptronAI | Medium</td>\n      <td>Attention has become the core operation in modern deep learning models. Today most of the commercial large models use the attention mechanism in their architecture whether it be vision or language.</td>\n      <td><a href=\"https://medium.com/perceptronai/a-study-on-attention-mechanism-7d199cf783b6\" target=\"_blank\">https://medium.com/perceptronai/a-study-on-attention-mechanism-7d199cf783b6</a></td>\n    </tr>\n    <tr>\n      <td>Demystifying Attention Mechanisms: Self-Attention from Math to Code -I | by M K Pavan Kumar | Stackademic</td>\n      <td>Stackademic is a learning hub for programmers, devs, coders, and engineers. Our goal is to democratize free coding education for the world.</td>\n      <td><a href=\"https://blog.stackademic.com/demystifying-attention-mechanisms-self-attention-from-math-to-code-i-a935647f337c\" target=\"_blank\">https://blog.stackademic.com/demystifying-attention-mechanisms-self-attention-from-math-to-code-i-a935647f337c</a></td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}